import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# -----------------------------
# 1. 데이터 로드
# -----------------------------
df = pd.read_csv("fraud_detection_dataset.csv")

# -----------------------------
# 2. 피처(X) / 라벨(y) 분리
# -----------------------------
X = df.drop(columns=["transaction_id", "customer_id", "transaction_time", "is_fraud"])
y = df["is_fraud"]

# -----------------------------
# 3. 범주형 변수 처리 (One-Hot Encoding)
# -----------------------------
X = pd.get_dummies(X, columns=["transaction_type", "merchant_category", "device_type", "location"], drop_first=True)

# -----------------------------
# 4. 학습용 / 테스트용 데이터 분리
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# -----------------------------
# 5. 연속형 변수 스케일링
# -----------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# -----------------------------
# 6. 로지스틱 회귀 모델 학습 (기본)
# -----------------------------
# 기본 로지스틱 회귀 (class_weight='balanced' 제거)
model = LogisticRegression(max_iter=1000)
model.fit(X_train_scaled, y_train)

# -----------------------------
# 7. 테스트 데이터로 예측
# -----------------------------
y_pred = model.predict(X_test_scaled)

# -----------------------------
# 8. 모델 평가
# -----------------------------
print("=== Confusion Matrix ===")
print(confusion_matrix(y_test, y_pred))

print("\n=== Classification Report ===")
print(classification_report(y_test, y_pred))

# -----------------------------
# 9. 임계값(threshold) 조정 예시
# -----------------------------
y_proba = model.predict_proba(X_test_scaled)[:, 1]
y_pred_thresh = (y_proba > 0.3).astype(int)  # 임계값 0.3 적용

print("=== Confusion Matrix (Threshold=0.3) ===")
print(confusion_matrix(y_test, y_pred_thresh))

print("\n=== Classification Report (Threshold=0.3) ===")
print(classification_report(y_test, y_pred_thresh))


# is_fraud 컬럼의 값별 개수 확인
fraud_counts = df["is_fraud"].value_counts()
print(fraud_counts)

# 비율까지 확인하고 싶으면
fraud_ratio = df["is_fraud"].value_counts(normalize=True) * 100
print(fraud_ratio)

#즉, 정확도는 높지만 사기 거래를 하나도 잡지 못함 → Recall = 0%


#########################################################################################


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report

# 1. CSV 파일 불러오기
df = pd.read_csv("fraud_detection_dataset.csv")  # 파일 이름에 맞게 수정

# 2. Feature와 Label 분리
# 예시: is_fraud 제외하고 숫자형 컬럼만 선택
X = df.select_dtypes(include=["int64", "float64"])
y = df["is_fraud"]
  # "is_fraud" 제외한 나머지를 피처로 사용
y = df["is_fraud"]                 # 라벨

# 3. Train/Test split (테스트 20%, 사기 비율 유지)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 4. Random Forest 모델 학습
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# 5. 테스트셋 예측
y_pred = rf_model.predict(X_test)

# 6. Confusion Matrix 확인
cm = confusion_matrix(y_test, y_pred)
print("=== Confusion Matrix ===")
print(cm)

# 7. Precision, Recall, F1-score 확인
cr = classification_report(y_test, y_pred)
print("\n=== Classification Report ===")
print(cr)

#이 Confusion Matrix와 Classification Report를 보면 완벽하게 사기 거래와 정상 거래를 모두 맞춘 상태이지만
#좀 더 현실적인 불균형/복잡한 데이터셋을 만들어서, 사기 탐지 성능을 평가하고 임계값(threshold) 조정, Recall 향상까지 시뮬레이션하는 예제도 보여드릴 수 있습니다.



#########################################################################################

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from xgboost import XGBClassifier

# 1. CSV 불러오기
df = pd.read_csv("fraud_detection_dataset.csv")  # 파일 이름에 맞게 수정

# 2. 숫자형 피처만 사용
X = df.select_dtypes(include=["int64", "float64"]).drop(columns=["is_fraud"])
y = df["is_fraud"]

# 3. Train/Test split (테스트 20%, 사기 비율 유지)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 4. XGBoost 모델 학습
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_model.fit(X_train, y_train)

# 5. 테스트셋 예측
y_pred = xgb_model.predict(X_test)

# 6. Confusion Matrix 출력
cm = confusion_matrix(y_test, y_pred)
print("=== Confusion Matrix ===")
print(cm)

# 7. Classification Report 출력
cr = classification_report(y_test, y_pred)
print("\n=== Classification Report ===")
print(cr)


#XGBoost를 사용했는데도 사기 거래(1)를 하나도 잡지 못한 상태네요. Confusion Matrix를 보면:


#########################################################################################


